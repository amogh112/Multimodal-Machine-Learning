{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Facial Expression Recognition: A Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shan Li and Weihong Deng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Transition of facial expression recognition (FER) from  laboratory controlled to challenging in-the-wild conditions\n",
    "2. Deep neural nets used to learn discriminative representations for automatic FER.\n",
    "3. Focus of recent systems\n",
    "    - Overfitting because of lack of sufficient training data.\n",
    "    - Expression unrelated variations such as:\n",
    "        - Illumination\n",
    "        - Head Pose\n",
    "        - Identity Bias\n",
    "4. In this paper\n",
    "    - Available datasets\n",
    "        - Accepted data collection principles\n",
    "        - Accepted evaluation principles\n",
    "    - Standard pipeline of a deep FER system.\n",
    "        - Related background knowledge\n",
    "        - Suggestions of applicable implementations\n",
    "    - SotA in deep FER\n",
    "        - Strategies defined for\n",
    "            - Static \n",
    "            - Dynamic image sequences\n",
    "        - Their advantages and disadvantages.\n",
    "        - Performances on widely used benchmarks\n",
    "5. Additional related issues\n",
    "6. Application Scenarios\n",
    "7. Remaining challenges and corresponding opportunities\n",
    "8. Future direction for the design of robust deep FER systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Facial expressions are universal signals to convey their emotional states and intentions.\n",
    "2. Importance in sociable robotics, medical treatment, driver fatigue, surveillance, other HCI systems.\n",
    "3. FER systems ave been explored to encode expression information from facial representations.\n",
    "4. Ekman and Friesen defined six basic emotions - anger, disgust, fear, happiness, sadness, surprise, contempt(recently added [5]).\n",
    "5. Advanced research on neuroscience and psychology argued mode of six basic emotions are culture specific and not universal.\n",
    "\n",
    "**More things are discussed including what is covered by other surveys (not deep) read everything in highlight again and add to the notes, only taking down things that are relevant to take action for now.**\n",
    "\n",
    "Some challenges that need to be addressed are:\n",
    "- Subject identity biasHigh inter subject variations due to age gender, ethnic backgrounds, level of expressiveness.\n",
    "- Variations in pose\n",
    "- Variations in illumination\n",
    "- Occlusions\n",
    "- Large intra class variability.\n",
    "\n",
    "\n",
    "Further discussed in this paper:\n",
    "- Section 2: Datasets\n",
    "- Section 3: Three Main steps in a deep FER system\n",
    "- Section 4: Special network tricks for static and dynamic image sequences.\n",
    "- Section 5: Additonal related issues and other practicall scenarios.\n",
    "- Section 6: Challenges nad opportunities, potential future directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Facial Expression Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 main steps in automatic deep FER:\n",
    "- Pre processing \n",
    "- Deep feature learning\n",
    "- Deep feature classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variations irrelevant to facial expression recognition such as *different backgrounds, illuminations and head poses* are present. Before training the deep neural network to learn meaningful features, preprocessing required to **align and normalize the visual semantic information** conveyed by the face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Face Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Detect and align face, remove non face areas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face detection\n",
    " - Viola Jones is commonly used   // *comment read about viola jones - how to compare its accuracy and computation complexity(fact - its good for near frontal faces)*\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Alignment\n",
    "- Using coordinates of localized landmarks **reduces variation in face scale** and in **plane rotation**.\n",
    "- Methods(Table 2 compares the performance):\n",
    "    - Active Appearance model (AAM) is a generative model that optimizes the required parameters form holistic facial appearance and global shape patterns.\n",
    "    - In dicriminative models, mixture of trees (MoT) structured models and the discriminative response map fitting (DRMF) use part based approaches that represent the face via the local appearance information around each landmark.\n",
    "    - A number of discriminative models directly use a cascade of regression functions to map the image appearance to landmark locations and have shown better results. eg- the supervised descent method (SDM, implemented in IntraFace).\n",
    "    \n",
    "    **More approaches there make notes later, first make a baseline with the naive triangulation that you have chosen nowm then extend with what's used in OpenFace adn IntraFace etc.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is vital for successful generalization. There are two kinds of augmentations possible:\n",
    "- On the fly data augmentation\n",
    "   - Usually used in deep nets to avoid overfitting, during the training step input samples are randomly cropped(from 4 corners and center) and then flipped horizontally, leads to ten times larger dataset.\n",
    "   - Two common prediction modes are adopted, only center patch is used for  predicting or the prediction value is averaged over all ten crops.\n",
    "- Offline data augmentation\n",
    "    - Frequently used operations include random perturbations and transforms eg - shifting, skew, scaling, noise, contrast and color jittering. Common noise models, salt and pepper, speckle noise, gaussian noise.\n",
    "    - GAN\n",
    "    - **Other ways, note later.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Face Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for variations in **illumination** and **pose**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Illumination Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying illumination causes large intra-class(same expression) variance.\n",
    "Various algorithms analysed. See paper highlights and **copy here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Pose Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization techniques to yield fronal facial views for FER.\n",
    "- Most Popular [92 - Hassner et al.]; localise facial landmarks, a 3D texture reference model generic to all faces generated to efficiently estimate visible facial components. Initial frontalized face is synthesised by back projecting each input face image to the reference coordinate system.\n",
    "- [93 - Sagonas et al.] proposed effective statistical model to simultaneously localize landmarks and convert facial poses using only frontla faces. \n",
    "- Recently GAN techniques for frontal view synthesis such as FF-GAN, TP-GAN< DR-GAN proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deep networks for feature learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Deep Belief Network (DBN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Deep Autoencoder (DAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Facial Expression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike traditional methods where the feature extraction step and the feature classification step are independent, deep networks can perform FER in an end to end way (loss layer at the end).\n",
    "\n",
    "Alternatively, using SVMs (theoretically demonstrated in 130) /random forest is also useful as in [133, 134].\n",
    "\n",
    "Another approach  showed that the covariance descriptors computed on DCNN features and classification with Gaussian kernels on Symmetric Positive Definite (SPD) manifold are more efficient than the standard classification with the softmax layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The State of the Art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature divided into two main groups depending on the type of data. Deep FER networks for:\n",
    "    - Static images\n",
    "    - Dynamic Image Sequences\n",
    "    \n",
    "Overview of current deep FER systems wrt network *architecture* and *performance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Deep FER networks for static images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal information considered due to convenience of data processing and availability of the relevant training data and test material.\n",
    "Things covered:\n",
    "- Pre - training and fine tuning skills for FER\n",
    "- Review novel deep neural networks\n",
    "- Table 4 shows the current state of the art methods in the field that are explicitly conducted in a person independent protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Pre-training and fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct training of deep networks on relatively small datasets is prone to overfitting.\n",
    "\n",
    "- Many studies used **additional task-oriented data to pre-train** their self built networks.\n",
    "\n",
    "- **Pre-training on larger FR data** positively affects the emotion recognition accuracy, **further fine-tuing with additional FER datasets** can help improve the performance\n",
    "\n",
    "-  Instead of directly using the pre-trained or fine-tuned models to extract features on the target dataset, a **multistage fine-tuning\n",
    "strategy** [63] (see “Submission 3” in Fig. 3) can achieve better\n",
    "performance:\n",
    "    - After first stage fine tuning using FER 2013 pre trained model\n",
    "    - Second stage fine-tuning based on the training part of the target dataset (EmotiW) employed to refine the models to adapt to a more specific dataset(target dataset).\n",
    "\n",
    "- Although pre-training and fine-tuning on external FR data can\n",
    "indirectly avoid the problem of small training data, the networks\n",
    "are trained separately from the FER and the face-dominated\n",
    "information remains in the learned features which may weaken\n",
    "the networks ability to represent expressions. To eliminate this\n",
    "effect, a two-stage training algorithm FaceNet2ExpNet [111] was\n",
    "proposed (see Fig. 4). The fine-tuned face net serves as a good\n",
    "initialization for the expression net and is used to guide the\n",
    "learning of the convolutional layers only. And the fully connected\n",
    "layers are trained from scratch with expression information to\n",
    "regularize the training of the target FER net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Diverse Network Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Auxiliary blocks and layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 Network Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.5 Multitask Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6 Cascaded Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.7 Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.8 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarisation of the approaches and corresponding reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Deep FER networks for dynamic image sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Frame Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Expression Intensity Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Deep Spatio-temporal FER network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Additional Related Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Occlusion and non-frontal head pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 FER on infrared data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 FER on 3D static and dynamic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Facial Expression Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Visualisation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 Other special issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Challenges and Opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Facial Expression datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Incorporating other affective models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Dataset bias and imbalanced distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Multimodal Affect Recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
